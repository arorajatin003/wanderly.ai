{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "from tqdm import tqdm\n",
    "from spacy.tokens import DocBin\n",
    "import json\n",
    "from youtube_transcript_api import YouTubeTranscriptApi\n",
    "import string\n",
    "import contractions\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from googleapiclient.discovery import build\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_train_test_data(files,file_name):\n",
    "    classe = []\n",
    "    annotations = []\n",
    "    count = 0\n",
    "    for file in files:\n",
    "        json_f = open(F'D:/randomProjects/wamderly/data/annotations/{file}')\n",
    "        nlp = spacy.blank(\"en\")\n",
    "        training_data = json.load(json_f)\n",
    "        for i in training_data['classes']:\n",
    "            classe.append(i)\n",
    "        for i in training_data['annotations']:\n",
    "            annotations.append(i)\n",
    "        count = count + len(training_data['annotations'])\n",
    "    final_json_file = {'classe':list(set(classe)),'annotations':annotations}\n",
    "    with open(f'D:/randomProjects/wamderly/data/{file_name}.json', \"w\") as file:\n",
    "        json.dump(final_json_file, file, indent=4)\n",
    "\n",
    "    json_f = open(f'D:/randomProjects/wamderly/data/{file_name}.json')\n",
    "\n",
    "    # # nlp = spacy.blank(\"en\")\n",
    "    training_data = json.load(json_f)\n",
    "    # the DocBin will store the example documents\n",
    "    db = DocBin()\n",
    "    compleated=False\n",
    "    missing_sent = []\n",
    "    i=-1\n",
    "    while not compleated:\n",
    "        i = i+1\n",
    "        run = 0\n",
    "        try:\n",
    "            for text, annotations in tqdm(training_data['annotations'][i:]):\n",
    "                try:\n",
    "                    run = run+1\n",
    "                    doc = nlp.make_doc(text)\n",
    "                    ents = []\n",
    "                    for start, end, label in annotations['entities']:\n",
    "                        span = doc.char_span(start, end, label=label, alignment_mode='contract')\n",
    "                        ents.append(span)\n",
    "                    doc.ents = ents\n",
    "                    db.add(doc)\n",
    "                except:\n",
    "                    print(text)\n",
    "            db.to_disk(f\"D:/randomProjects/wamderly/data/{file_name}.spacy\")\n",
    "            print(\"Saved Success\")\n",
    "            compleated = True\n",
    "        except:\n",
    "            print('error')\n",
    "            i = i + run \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 269/410 [00:00<00:00, 1374.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 3/140 [00:00<00:00, 428.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/136 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/135 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/134 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/133 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/132 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/131 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/130 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 2/129 [00:00<00:00, 667.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/126 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▍       | 31/125 [00:00<00:00, 1276.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 93/93 [00:00<00:00, 1343.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Duccess\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 185/185 [00:00<00:00, 1796.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Duccess\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "annotations_files_train = [\n",
    "    'annotations_7cPLbiblb84.json',\n",
    "    'annotations_p0MvovsCxCk.json',\n",
    "    'annotations.json',\n",
    "    'annotations_5zA6OFpkPe0.json',\n",
    "]\n",
    "annotations_files_test = [\n",
    "    \n",
    "    'annotations_Lv0PkSkKeSo.json',\n",
    "    'annotation_rm_j6O8y148.json'\n",
    "]\n",
    "create_train_test_data(annotations_files_train,'train_data')\n",
    "create_train_test_data(annotations_files_test,'test_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! python -m spacy init fill-config ../configs/base_config.cfg ../configs/config.cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "# Model Training\n",
    "! python -m spacy train ../configs/config.cfg --output ../ --paths.train ../data/train_data.spacy --paths.dev ../data/test_data.spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Testing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_f = open(F'D:/randomProjects/wamderly/data/annotations/annotations_7cPLbiblb84.json')\n",
    "training_data = json.load(json_f)\n",
    "nlp = spacy.blank(\"en\")\n",
    "i = -1\n",
    "basic_database = dict()\n",
    "compleated=False\n",
    "while not compleated:\n",
    "        i = i+1\n",
    "        run = 0\n",
    "        try:\n",
    "            for text, annotations in tqdm(training_data['annotations'][i:]):\n",
    "                try:\n",
    "                    run = run+1\n",
    "                    for start, end, label in annotations['entities']:\n",
    "                        if label in basic_database.keys(): \n",
    "                            basic_database[str(label)].append(str(text[start:end]))\n",
    "                        else:\n",
    "                            basic_database[label] = []\n",
    "                            basic_database[str(label)].append(str(text[start:end]))\n",
    "                except:\n",
    "                    # print(text)\n",
    "                    continue\n",
    "            # db.to_disk(f\"D:/randomProjects/wamderly/data/{file_name}.spacy\")\n",
    "            print(\"Saved Duccess\")\n",
    "            compleated = True\n",
    "        except:\n",
    "            print('error')\n",
    "            i = i + run \n",
    "basic_database\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# Load your trained model\n",
    "nlp = spacy.load('../models/ner_mod/model-best')\n",
    "\n",
    "json_f = open(F'D:/randomProjects/wamderly/data/annotations/annotations_7cPLbiblb84.json')\n",
    "training_data = json.load(json_f)\n",
    "\n",
    "# Sample test texts and true entities\n",
    "test_data = training_data['annotations']\n",
    "\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "for text, annotations in test_data:\n",
    "    doc = nlp(text)\n",
    "    pred_entities = {(ent.start_char, ent.end_char): ent.label_ for ent in doc.ents}\n",
    "    true_entities = {(start, end): label for start, end, label in annotations[\"entities\"]}\n",
    "\n",
    "    all_offsets = set(pred_entities.keys()) | set(true_entities.keys())\n",
    "\n",
    "    for offset in all_offsets:\n",
    "        y_true.append(true_entities.get(offset, \"O\"))\n",
    "        y_pred.append(pred_entities.get(offset, \"O\"))\n",
    "\n",
    "# Create confusion matrix\n",
    "labels = sorted(set(y_true + y_pred))\n",
    "cm = confusion_matrix(y_true, y_pred, labels=labels)\n",
    "\n",
    "# Plot\n",
    "df_cm = pd.DataFrame(cm, index=labels, columns=labels)\n",
    "df_cm\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_report = classification_report(y_true, y_pred, labels=labels)\n",
    "print(\"Classification Report:\")\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key word Extractring "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# {\n",
    "#     'LEM':{\n",
    "#         'word': str,\n",
    "#         'ENT': str,\n",
    "#         'keywords': list,\n",
    "#         'suggested_by': list,\n",
    "#         'rating': int\n",
    "#     }\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import requests\n",
    "\n",
    "# # Replace with your API key and the channel ID\n",
    "# # API_KEY = \"YOUR_API_KEY\"\n",
    "# CHANNEL_ID = \"UC_P_sA6Jf3iSsFueMwIP3vg\"\n",
    "\n",
    "# # Construct the API request URL\n",
    "# # url = f\"https://www.googleapis.com/youtube/v3/channels?part=statistics&id={CHANNEL_ID}&key={API_KEY}\"\n",
    "# url = f\"https://www.googleapis.com/youtube/v3/videos?part=statistics&id={video_id}&key={API_KEY}\"\n",
    "\n",
    "# # Make the API request\n",
    "# response = requests.get(url)\n",
    "\n",
    "# # Check if the request was successful\n",
    "# if response.status_code == 200:\n",
    "#     # Parse the JSON response\n",
    "#     data = response.json()\n",
    "\n",
    "#     # Extract the subscriber count\n",
    "#     if 'items' in data and len(data['items']) > 0:\n",
    "#         # subscriber_count = data['items'][0]['statistics']['subscriberCount']\n",
    "#         # print(f\"Subscriber Count: {subscriber_count}\")\n",
    "#         print(data['items'])\n",
    "#     else:\n",
    "#         print(\"Channel not found or error in response.\")\n",
    "# else:\n",
    "#     print(f\"Error: {response.status_code}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "API_KEY = 'AIzaSyBG7X8oJ1CYdPZd7F4gSo605Jf-EfD7IHM'\n",
    "def get_video_statistics(video_id): \n",
    "    # video_id = '7cPLbiblb84'\n",
    "    try:\n",
    "        youtube = build('youtube', 'v3', developerKey=API_KEY)\n",
    "\n",
    "        request = youtube.videos().list(\n",
    "            part=['snippet','statistics'],\n",
    "            id=video_id\n",
    "        )\n",
    "        response = request.execute()\n",
    "        stats = response['items'][0]['statistics']\n",
    "        viewCount = stats['viewCount'] if 'viewCount' in stats.keys() else 0\n",
    "        likeCount = stats['likeCount'] if 'likeCount' in stats.keys() else 0\n",
    "        commentCount = stats['commentCount'] if 'commentCount' in stats.keys() else 0 \n",
    "        channelId = response['items'][0]['snippet']['channelId']\n",
    "        channel_name = response['items'][0]['snippet']['channelTitle']\n",
    "\n",
    "        print(response['items'][0]['statistics'],channelId,channel_name)\n",
    "        \n",
    "        return int(viewCount),int(likeCount),int(commentCount),channel_name,channelId\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_channel_statistics(channelId):\n",
    "    try:\n",
    "        youtube = build('youtube', 'v3', developerKey=API_KEY)\n",
    "        request_channel =  youtube.channels().list(\n",
    "            part=['statistics'],\n",
    "            id=channelId\n",
    "        )\n",
    "        response_channel = request_channel.execute()\n",
    "        subscriberCount= response_channel['items'][0]['statistics']['subscriberCount']\n",
    "        return int(subscriberCount)\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning_sentence(text):\n",
    "    text = text.lower()\n",
    "    PUNCT_TO_REMOVE = string.punctuation\n",
    "    ans = contractions.fix(text).translate(str.maketrans('', '', PUNCT_TO_REMOVE))\n",
    "    ans = ans.replace('music','')\n",
    "    ans = ans.replace(\"  \",' ')\n",
    "    ans = \" \".join(ans.split())\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p0MvovsCxCk\n",
      "{'viewCount': '276661', 'favoriteCount': '0', 'commentCount': '97'} UCoCU-RvDqV1JgmbRgh79UTQ Singhsman \n",
      "7cPLbiblb84\n",
      "{'viewCount': '2023225', 'likeCount': '16150', 'favoriteCount': '0', 'commentCount': '861'} UC_P_sA6Jf3iSsFueMwIP3vg TheSocialTraveller\n",
      "rm_j6O8y148\n",
      "{'viewCount': '172459', 'likeCount': '2277', 'favoriteCount': '0', 'commentCount': '78'} UCQ0X2x6lozB7qG30ctFeUiA Saturday Shooters\n",
      "Lv0PkSkKeSo\n",
      "{'viewCount': '115050', 'likeCount': '2196', 'favoriteCount': '0', 'commentCount': '189'} UC2N5r2FvEOiDPKvaLW9rivw Aniruddha Patil\n",
      "5zA6OFpkPe0\n",
      "{'viewCount': '10179', 'likeCount': '201', 'favoriteCount': '0', 'commentCount': '33'} UCCq9CLWwVP4fdYy2N_ypTjg Sisters vs Globe\n",
      "Oz18u64bM8I\n",
      "{'viewCount': '9910', 'likeCount': '169', 'favoriteCount': '0', 'commentCount': '36'} UC-w8ULGFYLrjbdsZ6twWO3Q Travel Tales\n",
      "p0MvovsCxCk\n",
      "{'viewCount': '276666', 'favoriteCount': '0', 'commentCount': '97'} UCoCU-RvDqV1JgmbRgh79UTQ Singhsman \n",
      "7cPLbiblb84\n",
      "{'viewCount': '2023225', 'likeCount': '16150', 'favoriteCount': '0', 'commentCount': '861'} UC_P_sA6Jf3iSsFueMwIP3vg TheSocialTraveller\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lemma_word</th>\n",
       "      <th>word</th>\n",
       "      <th>ENT</th>\n",
       "      <th>suggested_by</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sindhi dal pakwan</td>\n",
       "      <td>sindhi dal pakwan</td>\n",
       "      <td>{FOOD}</td>\n",
       "      <td>{Singhsman }</td>\n",
       "      <td>19.855516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dal pakwan</td>\n",
       "      <td>dal pakwan</td>\n",
       "      <td>{FOOD}</td>\n",
       "      <td>{Singhsman }</td>\n",
       "      <td>23.855597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>kudi chola chola bhatura</td>\n",
       "      <td>kudi chola chola bhatura</td>\n",
       "      <td>{FOOD}</td>\n",
       "      <td>{Singhsman }</td>\n",
       "      <td>19.855516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>moong dal</td>\n",
       "      <td>moong dal</td>\n",
       "      <td>{FOOD}</td>\n",
       "      <td>{Singhsman }</td>\n",
       "      <td>19.855516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>chickpea</td>\n",
       "      <td>chickpeas</td>\n",
       "      <td>{FOOD}</td>\n",
       "      <td>{Singhsman }</td>\n",
       "      <td>19.855516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>assalam wala</td>\n",
       "      <td>assalam wala</td>\n",
       "      <td>{FOOD SHOP}</td>\n",
       "      <td>{Travel Tales}</td>\n",
       "      <td>3.014544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>ram pura</td>\n",
       "      <td>ram pura</td>\n",
       "      <td>{LANDMARK}</td>\n",
       "      <td>{Travel Tales}</td>\n",
       "      <td>3.014544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>maggi</td>\n",
       "      <td>maggi</td>\n",
       "      <td>{FOOD}</td>\n",
       "      <td>{Travel Tales}</td>\n",
       "      <td>3.014544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>khana wali</td>\n",
       "      <td>khana wali</td>\n",
       "      <td>{LANDMARK}</td>\n",
       "      <td>{Travel Tales}</td>\n",
       "      <td>3.014544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>arun bhai</td>\n",
       "      <td>arun bhai</td>\n",
       "      <td>{FOOD SHOP}</td>\n",
       "      <td>{Travel Tales}</td>\n",
       "      <td>4.014544</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>187 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   lemma_word                      word          ENT  \\\n",
       "0           sindhi dal pakwan         sindhi dal pakwan       {FOOD}   \n",
       "1                  dal pakwan                dal pakwan       {FOOD}   \n",
       "2    kudi chola chola bhatura  kudi chola chola bhatura       {FOOD}   \n",
       "3                   moong dal                 moong dal       {FOOD}   \n",
       "4                    chickpea                 chickpeas       {FOOD}   \n",
       "..                        ...                       ...          ...   \n",
       "182              assalam wala              assalam wala  {FOOD SHOP}   \n",
       "183                  ram pura                  ram pura   {LANDMARK}   \n",
       "184                     maggi                     maggi       {FOOD}   \n",
       "185                khana wali                khana wali   {LANDMARK}   \n",
       "186                 arun bhai                 arun bhai  {FOOD SHOP}   \n",
       "\n",
       "       suggested_by     rating  \n",
       "0      {Singhsman }  19.855516  \n",
       "1      {Singhsman }  23.855597  \n",
       "2      {Singhsman }  19.855516  \n",
       "3      {Singhsman }  19.855516  \n",
       "4      {Singhsman }  19.855516  \n",
       "..              ...        ...  \n",
       "182  {Travel Tales}   3.014544  \n",
       "183  {Travel Tales}   3.014544  \n",
       "184  {Travel Tales}   3.014544  \n",
       "185  {Travel Tales}   3.014544  \n",
       "186  {Travel Tales}   4.014544  \n",
       "\n",
       "[187 rows x 5 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_video_ids = [\n",
    "    'p0MvovsCxCk',\n",
    "    '7cPLbiblb84',\n",
    "    'rm_j6O8y148',\n",
    "    'Lv0PkSkKeSo',\n",
    "    '5zA6OFpkPe0',\n",
    "    'Oz18u64bM8I',\n",
    "    'p0MvovsCxCk',\n",
    "    '7cPLbiblb84'\n",
    "]\n",
    "nlp_ner = spacy.load('../model-best')\n",
    "nlp     = spacy.load(\"en_core_web_sm\")\n",
    "ner     = dict()\n",
    "    \n",
    "for video_id in test_video_ids:\n",
    "    try:\n",
    "        print(video_id)\n",
    "        \n",
    "        viewCount,likeCount,commentCount,channel_name,channelId = get_video_statistics(video_id)\n",
    "        subscriberCount = get_channel_statistics(channelId)\n",
    "        \n",
    "        file = open(f'D:/randomProjects/wamderly/data/transcripts/transcript_{video_id}.txt',\"r\")\n",
    "        file_c = open(f'D:/randomProjects/wamderly/data/transcripts/transcript_{video_id}.txt',\"r\")\n",
    "        file_string = file_c.read()\n",
    "        for text in file:\n",
    "            doc_ner = nlp_ner(cleaning_sentence(text)) \n",
    "\n",
    "            for ent in doc_ner.ents:\n",
    "                # print(ent,'->', ent.label_)\n",
    "                \n",
    "                doc = nlp(ent.text)\n",
    "\n",
    "                rating = file_string.count(ent.text) + ((viewCount+likeCount+commentCount+subscriberCount)/(subscriberCount))\n",
    "        \n",
    "                lemma = ' '.join([token.lemma_ for token in doc])\n",
    "                if lemma in ner.keys():\n",
    "                    # ner[ent.label_].append(ent.text)\n",
    "                    ner[lemma]['ENT'].add(ent.label_)\n",
    "                    ner[lemma]['rating'] = (rating+ner[lemma]['rating'])/2\n",
    "                    ner[lemma]['suggested_by'].add(channel_name)\n",
    "                else:\n",
    "                    # ner[ent.label_] = [ent.text]\n",
    "                    ner[lemma] = {\n",
    "                        'word': ent.text,\n",
    "                        'ENT': set([ent.label_]),\n",
    "                        # 'keywords': list,\n",
    "                        'suggested_by': set([channel_name]),\n",
    "                        'rating': rating\n",
    "                    }\n",
    "            # print('--x-x-x--x-x-x-x-x-x-x---x-x-x--')\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "# tokkenization()\n",
    "df = pd.DataFrame(ner)\n",
    "df = df.T\n",
    "df = df.reset_index().rename(columns={'index':'lemma_word'})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ENT_len'] = df['ENT'].apply(lambda x: len(list(x))) \n",
    "df['ENT_max'] = df['ENT'].apply(lambda x: (list(x))[0])\n",
    "# df = df[df['ENT_len']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lemma_word</th>\n",
       "      <th>word</th>\n",
       "      <th>ENT</th>\n",
       "      <th>suggested_by</th>\n",
       "      <th>rating</th>\n",
       "      <th>ENT_len</th>\n",
       "      <th>ENT_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>chickpea</td>\n",
       "      <td>chickpeas</td>\n",
       "      <td>{FOOD}</td>\n",
       "      <td>{Singhsman }</td>\n",
       "      <td>19.855516</td>\n",
       "      <td>1</td>\n",
       "      <td>FOOD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>kacha papad of which thing be you make spinach...</td>\n",
       "      <td>kacha papad of which thing are you making spin...</td>\n",
       "      <td>{FOOD SHOP}</td>\n",
       "      <td>{Singhsman }</td>\n",
       "      <td>19.855516</td>\n",
       "      <td>1</td>\n",
       "      <td>FOOD SHOP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>skykisse tower</td>\n",
       "      <td>skykissing tower</td>\n",
       "      <td>{LANDMARK}</td>\n",
       "      <td>{TheSocialTraveller}</td>\n",
       "      <td>35.611796</td>\n",
       "      <td>1</td>\n",
       "      <td>LANDMARK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>khilwat niwa</td>\n",
       "      <td>khilwat niwas</td>\n",
       "      <td>{LANDMARK}</td>\n",
       "      <td>{TheSocialTraveller}</td>\n",
       "      <td>35.611796</td>\n",
       "      <td>1</td>\n",
       "      <td>LANDMARK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>lakshmi vila</td>\n",
       "      <td>lakshmi vilas</td>\n",
       "      <td>{LANDMARK}</td>\n",
       "      <td>{TheSocialTraveller}</td>\n",
       "      <td>36.611796</td>\n",
       "      <td>1</td>\n",
       "      <td>LANDMARK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>strictly follow</td>\n",
       "      <td>strictly followed</td>\n",
       "      <td>{LANDMARK}</td>\n",
       "      <td>{TheSocialTraveller}</td>\n",
       "      <td>36.611796</td>\n",
       "      <td>1</td>\n",
       "      <td>LANDMARK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>daytoday activity</td>\n",
       "      <td>daytoday activities</td>\n",
       "      <td>{LANDMARK}</td>\n",
       "      <td>{TheSocialTraveller}</td>\n",
       "      <td>36.611796</td>\n",
       "      <td>1</td>\n",
       "      <td>LANDMARK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>diwane kha</td>\n",
       "      <td>diwane khas</td>\n",
       "      <td>{LANDMARK}</td>\n",
       "      <td>{TheSocialTraveller}</td>\n",
       "      <td>36.611796</td>\n",
       "      <td>1</td>\n",
       "      <td>LANDMARK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>sun ray</td>\n",
       "      <td>sun rays</td>\n",
       "      <td>{LANDMARK}</td>\n",
       "      <td>{Saturday Shooters}</td>\n",
       "      <td>3.533456</td>\n",
       "      <td>1</td>\n",
       "      <td>LANDMARK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>start</td>\n",
       "      <td>starting</td>\n",
       "      <td>{AREA}</td>\n",
       "      <td>{Saturday Shooters}</td>\n",
       "      <td>3.533456</td>\n",
       "      <td>1</td>\n",
       "      <td>AREA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            lemma_word  \\\n",
       "4                                             chickpea   \n",
       "37   kacha papad of which thing be you make spinach...   \n",
       "51                                      skykisse tower   \n",
       "75                                        khilwat niwa   \n",
       "78                                        lakshmi vila   \n",
       "112                                    strictly follow   \n",
       "113                                  daytoday activity   \n",
       "116                                         diwane kha   \n",
       "133                                            sun ray   \n",
       "137                                              start   \n",
       "\n",
       "                                                  word          ENT  \\\n",
       "4                                            chickpeas       {FOOD}   \n",
       "37   kacha papad of which thing are you making spin...  {FOOD SHOP}   \n",
       "51                                    skykissing tower   {LANDMARK}   \n",
       "75                                       khilwat niwas   {LANDMARK}   \n",
       "78                                       lakshmi vilas   {LANDMARK}   \n",
       "112                                  strictly followed   {LANDMARK}   \n",
       "113                                daytoday activities   {LANDMARK}   \n",
       "116                                        diwane khas   {LANDMARK}   \n",
       "133                                           sun rays   {LANDMARK}   \n",
       "137                                           starting       {AREA}   \n",
       "\n",
       "             suggested_by     rating  ENT_len    ENT_max  \n",
       "4            {Singhsman }  19.855516        1       FOOD  \n",
       "37           {Singhsman }  19.855516        1  FOOD SHOP  \n",
       "51   {TheSocialTraveller}  35.611796        1   LANDMARK  \n",
       "75   {TheSocialTraveller}  35.611796        1   LANDMARK  \n",
       "78   {TheSocialTraveller}  36.611796        1   LANDMARK  \n",
       "112  {TheSocialTraveller}  36.611796        1   LANDMARK  \n",
       "113  {TheSocialTraveller}  36.611796        1   LANDMARK  \n",
       "116  {TheSocialTraveller}  36.611796        1   LANDMARK  \n",
       "133   {Saturday Shooters}   3.533456        1   LANDMARK  \n",
       "137   {Saturday Shooters}   3.533456        1       AREA  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['lemma_word']!=df['word']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lemma_word</th>\n",
       "      <th>word</th>\n",
       "      <th>ENT</th>\n",
       "      <th>suggested_by</th>\n",
       "      <th>rating</th>\n",
       "      <th>ENT_len</th>\n",
       "      <th>ENT_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>hawa mahal</td>\n",
       "      <td>hawa mahal</td>\n",
       "      <td>{LANDMARK}</td>\n",
       "      <td>{Aniruddha Patil, Sisters vs Globe, Saturday S...</td>\n",
       "      <td>69.611796</td>\n",
       "      <td>1</td>\n",
       "      <td>LANDMARK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>amer fort</td>\n",
       "      <td>amer fort</td>\n",
       "      <td>{LANDMARK}</td>\n",
       "      <td>{Aniruddha Patil, Sisters vs Globe, Saturday S...</td>\n",
       "      <td>46.011464</td>\n",
       "      <td>1</td>\n",
       "      <td>LANDMARK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>nahar</td>\n",
       "      <td>nahar</td>\n",
       "      <td>{LANDMARK}</td>\n",
       "      <td>{TheSocialTraveller}</td>\n",
       "      <td>44.611796</td>\n",
       "      <td>1</td>\n",
       "      <td>LANDMARK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>jantar mantar</td>\n",
       "      <td>jantar mantar</td>\n",
       "      <td>{LANDMARK}</td>\n",
       "      <td>{Aniruddha Patil, Saturday Shooters, TheSocial...</td>\n",
       "      <td>44.003196</td>\n",
       "      <td>1</td>\n",
       "      <td>LANDMARK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>albert hall</td>\n",
       "      <td>albert hall</td>\n",
       "      <td>{LANDMARK}</td>\n",
       "      <td>{TheSocialTraveller}</td>\n",
       "      <td>43.611796</td>\n",
       "      <td>1</td>\n",
       "      <td>LANDMARK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>jaigarh fort</td>\n",
       "      <td>jaigarh fort</td>\n",
       "      <td>{LANDMARK}</td>\n",
       "      <td>{Saturday Shooters, TheSocialTraveller}</td>\n",
       "      <td>43.378838</td>\n",
       "      <td>1</td>\n",
       "      <td>LANDMARK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>albert hall museum</td>\n",
       "      <td>albert hall museum</td>\n",
       "      <td>{LANDMARK}</td>\n",
       "      <td>{TheSocialTraveller}</td>\n",
       "      <td>42.611796</td>\n",
       "      <td>1</td>\n",
       "      <td>LANDMARK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>nahargarh</td>\n",
       "      <td>nahargarh</td>\n",
       "      <td>{LANDMARK}</td>\n",
       "      <td>{TheSocialTraveller}</td>\n",
       "      <td>41.611796</td>\n",
       "      <td>1</td>\n",
       "      <td>LANDMARK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>sheesh mahal</td>\n",
       "      <td>sheesh mahal</td>\n",
       "      <td>{LANDMARK}</td>\n",
       "      <td>{Aniruddha Patil, Saturday Shooters, TheSocial...</td>\n",
       "      <td>40.065608</td>\n",
       "      <td>1</td>\n",
       "      <td>LANDMARK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>jantarmantar</td>\n",
       "      <td>jantarmantar</td>\n",
       "      <td>{LANDMARK}</td>\n",
       "      <td>{TheSocialTraveller}</td>\n",
       "      <td>39.611796</td>\n",
       "      <td>1</td>\n",
       "      <td>LANDMARK</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             lemma_word                word         ENT  \\\n",
       "46           hawa mahal          hawa mahal  {LANDMARK}   \n",
       "67            amer fort           amer fort  {LANDMARK}   \n",
       "119               nahar               nahar  {LANDMARK}   \n",
       "58        jantar mantar       jantar mantar  {LANDMARK}   \n",
       "47          albert hall         albert hall  {LANDMARK}   \n",
       "66         jaigarh fort        jaigarh fort  {LANDMARK}   \n",
       "48   albert hall museum  albert hall museum  {LANDMARK}   \n",
       "72            nahargarh           nahargarh  {LANDMARK}   \n",
       "68         sheesh mahal        sheesh mahal  {LANDMARK}   \n",
       "59         jantarmantar        jantarmantar  {LANDMARK}   \n",
       "\n",
       "                                          suggested_by     rating  ENT_len  \\\n",
       "46   {Aniruddha Patil, Sisters vs Globe, Saturday S...  69.611796        1   \n",
       "67   {Aniruddha Patil, Sisters vs Globe, Saturday S...  46.011464        1   \n",
       "119                               {TheSocialTraveller}  44.611796        1   \n",
       "58   {Aniruddha Patil, Saturday Shooters, TheSocial...  44.003196        1   \n",
       "47                                {TheSocialTraveller}  43.611796        1   \n",
       "66             {Saturday Shooters, TheSocialTraveller}  43.378838        1   \n",
       "48                                {TheSocialTraveller}  42.611796        1   \n",
       "72                                {TheSocialTraveller}  41.611796        1   \n",
       "68   {Aniruddha Patil, Saturday Shooters, TheSocial...  40.065608        1   \n",
       "59                                {TheSocialTraveller}  39.611796        1   \n",
       "\n",
       "      ENT_max  \n",
       "46   LANDMARK  \n",
       "67   LANDMARK  \n",
       "119  LANDMARK  \n",
       "58   LANDMARK  \n",
       "47   LANDMARK  \n",
       "66   LANDMARK  \n",
       "48   LANDMARK  \n",
       "72   LANDMARK  \n",
       "68   LANDMARK  \n",
       "59   LANDMARK  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['ENT_max']=='LANDMARK'].sort_values(by='rating',ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lemma_word</th>\n",
       "      <th>word</th>\n",
       "      <th>ENT</th>\n",
       "      <th>suggested_by</th>\n",
       "      <th>rating</th>\n",
       "      <th>ENT_len</th>\n",
       "      <th>ENT_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>diwaneaam</td>\n",
       "      <td>diwaneaam</td>\n",
       "      <td>{FOOD}</td>\n",
       "      <td>{TheSocialTraveller}</td>\n",
       "      <td>37.611796</td>\n",
       "      <td>1</td>\n",
       "      <td>FOOD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>ramnivasgarden</td>\n",
       "      <td>ramnivasgarden</td>\n",
       "      <td>{FOOD}</td>\n",
       "      <td>{TheSocialTraveller}</td>\n",
       "      <td>35.611796</td>\n",
       "      <td>1</td>\n",
       "      <td>FOOD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>paneer</td>\n",
       "      <td>paneer</td>\n",
       "      <td>{FOOD}</td>\n",
       "      <td>{Singhsman }</td>\n",
       "      <td>34.855516</td>\n",
       "      <td>1</td>\n",
       "      <td>FOOD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>dal</td>\n",
       "      <td>dal</td>\n",
       "      <td>{FOOD}</td>\n",
       "      <td>{Singhsman }</td>\n",
       "      <td>33.855516</td>\n",
       "      <td>1</td>\n",
       "      <td>FOOD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>tea</td>\n",
       "      <td>tea</td>\n",
       "      <td>{FOOD}</td>\n",
       "      <td>{Singhsman }</td>\n",
       "      <td>31.855516</td>\n",
       "      <td>1</td>\n",
       "      <td>FOOD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dal pakwan</td>\n",
       "      <td>dal pakwan</td>\n",
       "      <td>{FOOD}</td>\n",
       "      <td>{Singhsman }</td>\n",
       "      <td>23.855597</td>\n",
       "      <td>1</td>\n",
       "      <td>FOOD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>paneer tikka</td>\n",
       "      <td>paneer tikka</td>\n",
       "      <td>{FOOD}</td>\n",
       "      <td>{Singhsman }</td>\n",
       "      <td>23.855516</td>\n",
       "      <td>1</td>\n",
       "      <td>FOOD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>rabri</td>\n",
       "      <td>rabri</td>\n",
       "      <td>{FOOD}</td>\n",
       "      <td>{Singhsman }</td>\n",
       "      <td>21.855637</td>\n",
       "      <td>1</td>\n",
       "      <td>FOOD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>chole</td>\n",
       "      <td>chole</td>\n",
       "      <td>{FOOD}</td>\n",
       "      <td>{Singhsman }</td>\n",
       "      <td>21.855516</td>\n",
       "      <td>1</td>\n",
       "      <td>FOOD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>tikki</td>\n",
       "      <td>tikki</td>\n",
       "      <td>{FOOD}</td>\n",
       "      <td>{Singhsman }</td>\n",
       "      <td>20.855516</td>\n",
       "      <td>1</td>\n",
       "      <td>FOOD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>dal ghee wali</td>\n",
       "      <td>dal ghee wali</td>\n",
       "      <td>{FOOD}</td>\n",
       "      <td>{Singhsman }</td>\n",
       "      <td>19.855516</td>\n",
       "      <td>1</td>\n",
       "      <td>FOOD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>paneer tikka butter masala</td>\n",
       "      <td>paneer tikka butter masala</td>\n",
       "      <td>{FOOD}</td>\n",
       "      <td>{Singhsman }</td>\n",
       "      <td>19.855516</td>\n",
       "      <td>1</td>\n",
       "      <td>FOOD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>khichha chaat</td>\n",
       "      <td>khichha chaat</td>\n",
       "      <td>{FOOD}</td>\n",
       "      <td>{Singhsman }</td>\n",
       "      <td>19.855516</td>\n",
       "      <td>1</td>\n",
       "      <td>FOOD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>dal kachori onion kachori</td>\n",
       "      <td>dal kachori onion kachori</td>\n",
       "      <td>{FOOD}</td>\n",
       "      <td>{Singhsman }</td>\n",
       "      <td>19.855516</td>\n",
       "      <td>1</td>\n",
       "      <td>FOOD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>samosa wala</td>\n",
       "      <td>samosa wala</td>\n",
       "      <td>{FOOD}</td>\n",
       "      <td>{Singhsman }</td>\n",
       "      <td>19.855516</td>\n",
       "      <td>1</td>\n",
       "      <td>FOOD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sindhi dal pakwan</td>\n",
       "      <td>sindhi dal pakwan</td>\n",
       "      <td>{FOOD}</td>\n",
       "      <td>{Singhsman }</td>\n",
       "      <td>19.855516</td>\n",
       "      <td>1</td>\n",
       "      <td>FOOD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>bejar roti</td>\n",
       "      <td>bejar roti</td>\n",
       "      <td>{FOOD}</td>\n",
       "      <td>{Singhsman }</td>\n",
       "      <td>19.855516</td>\n",
       "      <td>1</td>\n",
       "      <td>FOOD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>garlic chutney</td>\n",
       "      <td>garlic chutney</td>\n",
       "      <td>{FOOD}</td>\n",
       "      <td>{Singhsman }</td>\n",
       "      <td>19.855516</td>\n",
       "      <td>1</td>\n",
       "      <td>FOOD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>malai paneer tikka</td>\n",
       "      <td>malai paneer tikka</td>\n",
       "      <td>{FOOD}</td>\n",
       "      <td>{Singhsman }</td>\n",
       "      <td>19.855516</td>\n",
       "      <td>1</td>\n",
       "      <td>FOOD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>paneer sill paneer raw paneer</td>\n",
       "      <td>paneer sill paneer raw paneer</td>\n",
       "      <td>{FOOD}</td>\n",
       "      <td>{Singhsman }</td>\n",
       "      <td>19.855516</td>\n",
       "      <td>1</td>\n",
       "      <td>FOOD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>tamarind chutney</td>\n",
       "      <td>tamarind chutney</td>\n",
       "      <td>{FOOD}</td>\n",
       "      <td>{Singhsman }</td>\n",
       "      <td>19.855516</td>\n",
       "      <td>1</td>\n",
       "      <td>FOOD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>chickpea</td>\n",
       "      <td>chickpeas</td>\n",
       "      <td>{FOOD}</td>\n",
       "      <td>{Singhsman }</td>\n",
       "      <td>19.855516</td>\n",
       "      <td>1</td>\n",
       "      <td>FOOD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>moong dal</td>\n",
       "      <td>moong dal</td>\n",
       "      <td>{FOOD}</td>\n",
       "      <td>{Singhsman }</td>\n",
       "      <td>19.855516</td>\n",
       "      <td>1</td>\n",
       "      <td>FOOD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>kudi chola chola bhatura</td>\n",
       "      <td>kudi chola chola bhatura</td>\n",
       "      <td>{FOOD}</td>\n",
       "      <td>{Singhsman }</td>\n",
       "      <td>19.855516</td>\n",
       "      <td>1</td>\n",
       "      <td>FOOD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>stepwell</td>\n",
       "      <td>stepwell</td>\n",
       "      <td>{FOOD}</td>\n",
       "      <td>{Aniruddha Patil}</td>\n",
       "      <td>5.37163</td>\n",
       "      <td>1</td>\n",
       "      <td>FOOD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>tuktuk</td>\n",
       "      <td>tuktuk</td>\n",
       "      <td>{FOOD}</td>\n",
       "      <td>{Saturday Shooters}</td>\n",
       "      <td>3.533456</td>\n",
       "      <td>1</td>\n",
       "      <td>FOOD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>doobi</td>\n",
       "      <td>doobi</td>\n",
       "      <td>{FOOD}</td>\n",
       "      <td>{Travel Tales}</td>\n",
       "      <td>3.014544</td>\n",
       "      <td>1</td>\n",
       "      <td>FOOD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>maggi</td>\n",
       "      <td>maggi</td>\n",
       "      <td>{FOOD}</td>\n",
       "      <td>{Travel Tales}</td>\n",
       "      <td>3.014544</td>\n",
       "      <td>1</td>\n",
       "      <td>FOOD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>kesar kari bagh</td>\n",
       "      <td>kesar kari bagh</td>\n",
       "      <td>{FOOD}</td>\n",
       "      <td>{Aniruddha Patil}</td>\n",
       "      <td>2.37163</td>\n",
       "      <td>1</td>\n",
       "      <td>FOOD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>sambar salt</td>\n",
       "      <td>sambar salt</td>\n",
       "      <td>{FOOD}</td>\n",
       "      <td>{Aniruddha Patil}</td>\n",
       "      <td>2.37163</td>\n",
       "      <td>1</td>\n",
       "      <td>FOOD</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        lemma_word                           word     ENT  \\\n",
       "124                      diwaneaam                      diwaneaam  {FOOD}   \n",
       "62                  ramnivasgarden                 ramnivasgarden  {FOOD}   \n",
       "10                          paneer                         paneer  {FOOD}   \n",
       "5                              dal                            dal  {FOOD}   \n",
       "25                             tea                            tea  {FOOD}   \n",
       "1                       dal pakwan                     dal pakwan  {FOOD}   \n",
       "16                    paneer tikka                   paneer tikka  {FOOD}   \n",
       "20                           rabri                          rabri  {FOOD}   \n",
       "6                            chole                          chole  {FOOD}   \n",
       "39                           tikki                          tikki  {FOOD}   \n",
       "43                   dal ghee wali                  dal ghee wali  {FOOD}   \n",
       "42      paneer tikka butter masala     paneer tikka butter masala  {FOOD}   \n",
       "36                   khichha chaat                  khichha chaat  {FOOD}   \n",
       "28       dal kachori onion kachori      dal kachori onion kachori  {FOOD}   \n",
       "26                     samosa wala                    samosa wala  {FOOD}   \n",
       "0                sindhi dal pakwan              sindhi dal pakwan  {FOOD}   \n",
       "22                      bejar roti                     bejar roti  {FOOD}   \n",
       "21                  garlic chutney                 garlic chutney  {FOOD}   \n",
       "12              malai paneer tikka             malai paneer tikka  {FOOD}   \n",
       "11   paneer sill paneer raw paneer  paneer sill paneer raw paneer  {FOOD}   \n",
       "7                 tamarind chutney               tamarind chutney  {FOOD}   \n",
       "4                         chickpea                      chickpeas  {FOOD}   \n",
       "3                        moong dal                      moong dal  {FOOD}   \n",
       "2         kudi chola chola bhatura       kudi chola chola bhatura  {FOOD}   \n",
       "142                       stepwell                       stepwell  {FOOD}   \n",
       "135                         tuktuk                         tuktuk  {FOOD}   \n",
       "181                          doobi                          doobi  {FOOD}   \n",
       "184                          maggi                          maggi  {FOOD}   \n",
       "147                kesar kari bagh                kesar kari bagh  {FOOD}   \n",
       "165                    sambar salt                    sambar salt  {FOOD}   \n",
       "\n",
       "             suggested_by     rating  ENT_len ENT_max  \n",
       "124  {TheSocialTraveller}  37.611796        1    FOOD  \n",
       "62   {TheSocialTraveller}  35.611796        1    FOOD  \n",
       "10           {Singhsman }  34.855516        1    FOOD  \n",
       "5            {Singhsman }  33.855516        1    FOOD  \n",
       "25           {Singhsman }  31.855516        1    FOOD  \n",
       "1            {Singhsman }  23.855597        1    FOOD  \n",
       "16           {Singhsman }  23.855516        1    FOOD  \n",
       "20           {Singhsman }  21.855637        1    FOOD  \n",
       "6            {Singhsman }  21.855516        1    FOOD  \n",
       "39           {Singhsman }  20.855516        1    FOOD  \n",
       "43           {Singhsman }  19.855516        1    FOOD  \n",
       "42           {Singhsman }  19.855516        1    FOOD  \n",
       "36           {Singhsman }  19.855516        1    FOOD  \n",
       "28           {Singhsman }  19.855516        1    FOOD  \n",
       "26           {Singhsman }  19.855516        1    FOOD  \n",
       "0            {Singhsman }  19.855516        1    FOOD  \n",
       "22           {Singhsman }  19.855516        1    FOOD  \n",
       "21           {Singhsman }  19.855516        1    FOOD  \n",
       "12           {Singhsman }  19.855516        1    FOOD  \n",
       "11           {Singhsman }  19.855516        1    FOOD  \n",
       "7            {Singhsman }  19.855516        1    FOOD  \n",
       "4            {Singhsman }  19.855516        1    FOOD  \n",
       "3            {Singhsman }  19.855516        1    FOOD  \n",
       "2            {Singhsman }  19.855516        1    FOOD  \n",
       "142     {Aniruddha Patil}    5.37163        1    FOOD  \n",
       "135   {Saturday Shooters}   3.533456        1    FOOD  \n",
       "181        {Travel Tales}   3.014544        1    FOOD  \n",
       "184        {Travel Tales}   3.014544        1    FOOD  \n",
       "147     {Aniruddha Patil}    2.37163        1    FOOD  \n",
       "165     {Aniruddha Patil}    2.37163        1    FOOD  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['ENT_max']=='FOOD'].sort_values(by='rating',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_context_window(id, text, window_size=50):\n",
    "    file = open(f'D:/randomProjects/wamderly/data/transcripts/transcript_{id}.txt',\"r\")\n",
    "    file_string = file.read()\n",
    "    # loc = 'city palace'\n",
    "    start = file_string.find(text)\n",
    "    end = file_string.rfind(text)\n",
    "    context_text = (file_string[start-window_size:end+window_size])\n",
    "    return context_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s the next place which you can visit in jaipur is city palace\\nwhen you buy the ticket you will also get a map here so that you will be able to see which places you can visit\\nas soon as you enter the city palace the first thing you will see is mubarak mahal\\nafter the taj mahal this is the most beautiful place in india\\nthis is the second building which is visible from all sides\\nat this time a museum has been built inside mubarak mahal where photography is not allowed\\napart from this you can visit the art gallery weapon gallery and after this you can visit diwan aam and diwan khas\\nhere you will get to see a jug made of silver which is the worlds biggest jug\\nthe height of this jug is 53 feet and its weight is 300 kg without water and with water its weight becomes about 4000 kg\\nthe name of this jug is also included in the gis book of world records\\nthe timings to visit here are from 930 am to 730 pm\\nthese people give the last entry till around 600 pm\\nafter this the next place which you can visit in jaipur is jantar mantar\\njantar mantar is situated just next to the city palace\\nkeep one thing in mind that you should'"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_context_window('rm_j6O8y148','city palace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\Jatin\n",
      "[nltk_data]     Arora\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from rake_nltk import Rake\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Uses stopwords for english from NLTK, and all puntuation characters by\n",
    "# default\n",
    "r = Rake()\n",
    "\n",
    "# Extraction given the text.\n",
    "a = get_context_window('rm_j6O8y148','city palace')\n",
    "# r.extract_keywords_from_text(a.replace('\\n',\" \"))\n",
    "\n",
    "# Extraction given the list of strings where each string is a sentence.\n",
    "r.extract_keywords_from_sentences(a.replace('\\n',\" \"))\n",
    "\n",
    "# To get keyword phrases ranked highest to lowest.\n",
    "# r.get_ranked_phrases()\n",
    "\n",
    "# To get keyword phrases ranked highest to lowest with scores.\n",
    "b = r.get_ranked_phrases_with_scores()\n",
    "for rating,keyword in b:\n",
    "    if rating>5:\n",
    "        print(rating,keyword)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
